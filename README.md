# 52CV-WACV-Papers


# :exclamation::exclamation::exclamation::star2::star2::star2:ğŸ“—ğŸ“—ğŸ“—WACV 2022æ”¶å½•è®ºæ–‡å·²å…¨éƒ¨å…¬å¸ƒï¼Œä¸‹è½½å¯åœ¨ã€æˆ‘çˆ±è®¡ç®—æœºè§†è§‰ã€‘åå°å›å¤â€œpaperâ€ï¼Œå³å¯æ”¶åˆ°ã€‚å…±è®¡ 406 ç¯‡ã€‚

# :exclamation::exclamation::exclamation::star2::star2::star2:è¿‘æœŸä¼šæŒç»­å¯¹è¯¥ä¼šè®ºæ–‡è¿›è¡Œåˆ†ç±»ï¼Œæ–½å·¥ä¸­......

# ç›®å½•

|:dog:|:mouse:|:hamster:|:tiger:|
|------|------|------|------|




## éŸ³é¢‘å¤„ç†
* [Beyond Mono to Binaural: Generating Binaural Audio From Mono Audio With Depth and Cross Modal Attention](https://arxiv.org/abs/2111.08046)<br>:house:[project](https://krantiparida.github.io/projects/bmonobinaural.html)
* éŸ³ç‰©å®šä½
  * [Unsupervised Sounding Object Localization With Bottom-Up and Top-Down Attention](https://openaccess.thecvf.com/content/WACV2022/papers/Shi_Unsupervised_Sounding_Object_Localization_With_Bottom-Up_and_Top-Down_Attention_WACV_2022_paper.pdf)<br>:star:[code](https://github.com/VISION-SJTU/USOL)



## Light Fields(å…‰åœº)
* [Fast and Efficient Restoration of Extremely Dark Light Fields](https://openaccess.thecvf.com/content/WACV2022/papers/Lamba_Fast_and_Efficient_Restoration_of_Extremely_Dark_Light_Fields_WACV_2022_paper.pdf)


## 28.Object Pose Estimation(ç‰©ä½“å§¿æ€ä¼°è®¡)
* [Occlusion-Robust Object Pose Estimation with Holistic Representation](https://arxiv.org/abs/2110.11636)<br>:star:[code](https://github.com/BoChenYS/ROPE)

## 27.Defect Detection(ç¼ºé™·æ£€æµ‹)
* [Fully Convolutional Cross-Scale-Flows for Image-Based Defect Detection](https://arxiv.org/abs/2110.02855)<br>:star:[code](https://github.com/marco-rudolph/cs-flow)


## 26.Dataset(æ•°æ®é›†)
* [MovingFashion: A Benchmark for the Video-To-Shop Challenge](https://arxiv.org/abs/2110.02627)<br>:sunflower:[dataset](https://github.com/HumaticsLAB/SEAM-Match-RCNN)


## 25.Image Captioning(å›¾åƒå­—å¹•)
* [Is an Image Worth Five Sentences? A New Look Into Semantics for Image-Text Matching](https://openaccess.thecvf.com/content/WACV2022/papers/Biten_Is_an_Image_Worth_Five_Sentences_A_New_Look_Into_WACV_2022_paper.pdf)<br>:star:[code](https://github.com/furkanbiten/ncs_metric):star:[code](https://github.com/andrespmd/semantic_adaptive_margin)
* [Let There Be a Clock on the Beach: Reducing Object Hallucination in Image Captioning](https://openaccess.thecvf.com/content/WACV2022/papers/Biten_Let_There_Be_a_Clock_on_the_Beach_Reducing_Object_WACV_2022_paper.pdf)<br>:star:[code](https://github.com/furkanbiten/object-bias)


## 24.Image Retrieval(å›¾åƒæ£€ç´¢)
* [All the Attention You Need: Global-Local, Spatial-Channel Attention for Image Retrieval](https://arxiv.org/abs/2107.08000)


## 23.Autonomous Driving(æ™ºèƒ½é©¾é©¶)
* è‡ªåŠ¨é©¾é©¶
  * [Multi-View Fusion of Sensor Data for Improved Perception and Prediction in Autonomous Driving](https://arxiv.org/abs/2008.11901)
  * ç›®æ ‡æ£€æµ‹
   * [Adversarial Robustness of Deep Sensor Fusion Models](https://arxiv.org/abs/2006.13192)

## 22.Human Action Recognition(äººä½“åŠ¨ä½œè¯†åˆ«ä¸æ£€æµ‹)
* [NUTA: Non-Uniform Temporal Aggregation for Action Recognition](https://arxiv.org/abs/2012.08041)
* [MM-ViT: Multi-Modal Video Transformer for Compressed Video Action Recognition](https://openaccess.thecvf.com/content/WACV2022/papers/Chen_MM-ViT_Multi-Modal_Video_Transformer_for_Compressed_Video_Action_Recognition_WACV_2022_paper.pdf)
* [Dual-Head Contrastive Domain Adaptation for Video Action Recognition](https://openaccess.thecvf.com/content/WACV2022/papers/da_Costa_Dual-Head_Contrastive_Domain_Adaptation_for_Video_Action_Recognition_WACV_2022_paper.pdf)(https://github.com/vturrisi/CO2A)

## 21.Point Cloud(ç‚¹äº‘)
* 3D ç‚¹äº‘
  * [Spatial-Temporal Transformer for 3D Point Cloud Sequences](https://arxiv.org/abs/2110.09783)
  * 3Dç‚¹äº‘ç›®æ ‡åˆ†ç±»
    * [What Makes for Effective Few-Shot Point Cloud Classification?](https://openaccess.thecvf.com/content/WACV2022/papers/Ye_What_Makes_for_Effective_Few-Shot_Point_Cloud_Classification_WACV_2022_paper.pdf)

## 20.Transformer
* å›¾åƒåˆ†ç±»
  * [Resource-Efficient Hybrid X-Formers for Vision](https://openaccess.thecvf.com/content/WACV2022/papers/Jeevan_Resource-Efficient_Hybrid_X-Formers_for_Vision_WACV_2022_paper.pdf)<br>:star:[code](https://github.com/pranavphoenix/VisionXformer)

## 19.Model Compression\Knowledge Distillation\Pruning(æ¨¡å‹å‹ç¼©\çŸ¥è¯†è’¸é¦\å‰ªæ)
* æ¨¡å‹å‹ç¼©
  * [Model Compression Using Optimal Transport](https://arxiv.org/abs/2012.03907)
* çŸ¥è¯†è’¸é¦
  * [Extractive Knowledge Distillation](https://openaccess.thecvf.com/content/WACV2022/papers/Kobayashi_Extractive_Knowledge_Distillation_WACV_2022_paper.pdf)
* å‰ªæ
  * [Hessian-Aware Pruning and Optimal Neural Implant](http://arxiv.org/abs/2101.08940)<br>:star:[code](https://github.com/yaozhewei/HAP)

## 18.NAS(ç¥ç»æ¶æ„æœç´¢)
* [Approximate Neural Architecture Search via Operation Distribution Learning](https://openaccess.thecvf.com/content/WACV2022/papers/Wan_Approximate_Neural_Architecture_Search_via_Operation_Distribution_Learning_WACV_2022_paper.pdf)
* [Neural Architecture Search for Efficient Uncalibrated Deep Photometric Stereo](https://arxiv.org/abs/2110.05621)


## 17.OCR(æ–‡æœ¬æ£€æµ‹)
* [Post-OCR Paragraph Recognition by Graph Convolutional Networks](https://arxiv.org/abs/2101.12741)


## 16.Super-Resolution(è¶…åˆ†è¾¨ç‡)
* [Normalizing Flow as a Flexible Fidelity Objective for Photo-Realistic Super-Resolution](https://arxiv.org/abs/2111.03649)<br>:star:[code](https://github.com/andreas128/AdFlow?1)
* [Multi-Dimensional Dynamic Model Compression for Efficient Image Super-Resolution](https://openaccess.thecvf.com/content/WACV2022/papers/Hou_Multi-Dimensional_Dynamic_Model_Compression_for_Efficient_Image_Super-Resolution_WACV_2022_paper.pdf)
* [edge-SR: Super-Resolution for the Masses](https://openaccess.thecvf.com/content/WACV2022/papers/Michelini_edge-SR_Super-Resolution_for_the_Masses_WACV_2022_paper.pdf)
* BSR
  * [MoESR: Blind Super-Resolution Using Kernel-Aware Mixture of Experts](https://openaccess.thecvf.com/content/WACV2022/papers/Emad_MoESR_Blind_Super-Resolution_Using_Kernel-Aware_Mixture_of_Experts_WACV_2022_paper.pdf)<br>:star:[code](https://github.com/memad73/MoESR)

## 15.Image Synthesis(å›¾åƒåˆæˆ)
* sketch-to-photo
  * [Adversarial Open Domain Adaptation for Sketch-to-Photo Synthesis](https://arxiv.org/abs/2104.05703)<br>:star:[code](https://github.com/Mukosame/AODA)
* Image-to-Image Translation
  * [Evaluation of Correctness in Unsupervised Many-to-Many Image Translation](https://arxiv.org/abs/2103.15727)<br>:star:[code](https://github.com/dbash/umi2i_correctness)

## 14.Semi-Supervised Learning(åŠç›‘ç£å­¦ä¹ )
* åŠç›‘ç£
  * [HierMatch: Leveraging Label Hierarchies for Improving Semi-Supervised Learning](https://arxiv.org/abs/2111.00164)<br>:star:[code](https://github.com/07Agarg/HIERMATCHï¼‰

## 13.Image Segmentation(å›¾åƒåˆ†å‰²)
* [Semantically Stealthy Adversarial Attacks Against Segmentation Models](https://arxiv.org/abs/2104.01732)
* è§†é¢‘åˆ†å‰²
  * [D2Conv3D: Dynamic Dilated Convolutions for Object Segmentation in Videos](https://openaccess.thecvf.com/content/WACV2022/papers/Schmidt_D2Conv3D_Dynamic_Dilated_Convolutions_for_Object_Segmentation_in_Videos_WACV_2022_paper.pdf)<br>:star:[code](https://github.com/Schmiddo/d2conv3d)
* VOS(è§†é¢‘ç›®æ ‡åˆ†å‰²)
  * [Pixel-Level Bijective Matching for Video Object Segmentation](https://arxiv.org/abs/2110.01644)<br>:star:[code](https://github.com/suhwan-cho/BMVOS)
* è¯­ä¹‰åˆ†å‰²
  * [A Pixel-Level Meta-Learner for Weakly Supervised Few-Shot Semantic Segmentation](https://arxiv.org/abs/2111.01418)
  * [Plugging Self-Supervised Monocular Depth Into Unsupervised Domain Adaptation for Semantic Segmentation](https://arxiv.org/abs/2110.06685)<br>:star:[code](https://github.com/CVLAB-Unibo/d4-dbst)
  * [Inferring the Class Conditional Response Map for Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2110.14309)<br>:star:[code](https://github.com/weixuansun/InferCam)
  * å°æ ·æœ¬è¯­ä¹‰åˆ†å‰²
    * [Pixel-by-Pixel Cross-Domain Alignment for Few-Shot Semantic Segmentation](https://arxiv.org/abs/2110.11650)<br>:star:[code](https://github.com/taveraantonio/PixDA)
* è¶…åƒç´ åˆ†å‰²
  * [HERS Superpixels: Deep Affinity Learning for Hierarchical Entropy Rate Segmentation](https://openaccess.thecvf.com/content/WACV2022/papers/Peng_HERS_Superpixels_Deep_Affinity_Learning_for_Hierarchical_Entropy_Rate_Segmentation_WACV_2022_paper.pdf)<br>:star:[code](https://github.com/hankuipeng/DAL-HERS)
* é“è·¯åˆ†å‰²
 * [VCSeg: Virtual Camera Adaptation for Road Segmentation](https://openaccess.thecvf.com/content/WACV2022/papers/Cheng_VCSeg_Virtual_Camera_Adaptation_for_Road_Segmentation_WACV_2022_paper.pdf)

## 12.Few-Shot Learning or Domain Adaptation\Generalization(å°æ ·æœ¬å­¦ä¹  or åŸŸé€‚åº”\æ³›åŒ–)
* å¼€é›†åŸŸé€‚åº”
  * [Distance-based Hyperspherical Classification for Multi-source Open-Set Domain Adaptation](https://arxiv.org/abs/2107.02067)<br>:star:[code](https://github.com/silvia1993/HyMOS)
* åŸŸæ³›åŒ–
  * [Learning to Weight Filter Groups for Robust Classification](https://openaccess.thecvf.com/content/WACV2022/papers/Yuan_Learning_to_Weight_Filter_Groups_for_Robust_Classification_WACV_2022_paper.pdf)
* å°æ ·æœ¬å­¦ä¹ 
  * [Contextual Gradient Scaling for Few-Shot Learning](https://arxiv.org/abs/2110.10353)<br>:star:[code](https://github.com/shlee625/CxGrad)

## 11.Face(äººè„¸)
* 3D Facial
  * äººè„¸è¡¨æƒ…
    * [Information Bottlenecked Variational Autoencoder for Disentangled 3D Facial Expression Modelling](https://openaccess.thecvf.com/content/WACV2022/papers/Sun_Information_Bottlenecked_Variational_Autoencoder_for_Disentangled_3D_Facial_Expression_Modelling_WACV_2022_paper.pdf)
  * 3Däººè„¸é‡å»º
     * [Occlusion Resistant Network for 3D Face Reconstruction](https://openaccess.thecvf.com/content/WACV2022/papers/Tiwari_Occlusion_Resistant_Network_for_3D_Face_Reconstruction_WACV_2022_paper.pdf)
* åŸºäºçš±çº¹çš„äººä½“è¯†åˆ«
  * [Mobile Based Human Identification Using Forehead Creases: Application and Assessment Under COVID-19 Masked Face Scenarios](https://openaccess.thecvf.com/content/WACV2022/papers/Bharadwaj_Mobile_Based_Human_Identification_Using_Forehead_Creases_Application_and_Assessment_WACV_2022_paper.pdf)
* äººè„¸æ´»ä½“æ£€æµ‹
  * [Disentangled Representation With Dual-Stage Feature Learning for Face Anti-Spoofing](https://arxiv.org/abs/2110.09157)
* äººè„¸è¡¨æƒ…
  * [Quantified Facial Expressiveness for Affective Behavior Analytics](https://arxiv.org/abs/2110.01758)

## 10.Adversarial Learning(å¯¹æŠ—å­¦ä¹ )
* é»‘ç›’æ”»å‡»
  * [On the Effectiveness of Small Input Noise for Defending Against Query-Based Black-Box Attacks](https://arxiv.org/abs/2101.04829)
* å¯¹æŠ—æ ·æœ¬
  * [Attack Agnostic Detection of Adversarial Examples via Random Subspace Analysis](https://arxiv.org/abs/2012.06405)
* å¯¹æŠ—æ”»å‡»
  * [Generative Adversarial Attack on Ensemble Clustering](https://openaccess.thecvf.com/content/WACV2022/papers/Kumar_Generative_Adversarial_Attack_on_Ensemble_Clustering_WACV_2022_paper.pdf)

## 9.Remote Sensing\Satellite Image(é¥æ„Ÿ\å«æ˜Ÿå›¾åƒ)
* [Lane-Level Street Map Extraction From Aerial Imagery](https://openaccess.thecvf.com/content/WACV2022/papers/He_Lane-Level_Street_Map_Extraction_From_Aerial_Imagery_WACV_2022_paper.pdf)
* å°æ ·æœ¬å¼€æ”¾é›†è¯†åˆ«
  * [Few-Shot Open-Set Recognition of Hyperspectral Images With Outlier Calibration Network](https://openaccess.thecvf.com/content/WACV2022/papers/Pal_Few-Shot_Open-Set_Recognition_of_Hyperspectral_Images_With_Outlier_Calibration_Network_WACV_2022_paper.pdf)<br>:star:[code](https://github.com/DebabrataPal7/OCN)
* å«æ˜Ÿå›¾åƒæ£€æµ‹
  * åœè½¦åœºæ£€æµ‹
    * [A Context-Enriched Satellite Imagery Dataset and an Approach for Parking Lot Detection](https://openaccess.thecvf.com/content/WACV2022/papers/Yin_A_Context-Enriched_Satellite_Imagery_Dataset_and_an_Approach_for_Parking_WACV_2022_paper.pdf)

## 8.Image Processing(å›¾åƒå¤„ç†)
* å»æ¨¡ç³Š
  * [Non-Blind Deblurring for Fluorescence: A Deformable Latent Space Approach With Kernel Parameterization](https://openaccess.thecvf.com/content/WACV2022/papers/Guan_Non-Blind_Deblurring_for_Fluorescence_A_Deformable_Latent_Space_Approach_With_WACV_2022_paper.pdf)
* å»é©¬èµ›å…‹
  * [Forgery Detection by Internal Positional Learning of Demosaicing Traces](https://openaccess.thecvf.com/content/WACV2022/papers/Bammey_Forgery_Detection_by_Internal_Positional_Learning_of_Demosaicing_Traces_WACV_2022_paper.pdf)
* å›¾åƒè£å‰ª
  * [Auditing Saliency Cropping Algorithms](https://openaccess.thecvf.com/content/WACV2022/papers/Birhane_Auditing_Saliency_Cropping_Algorithms_WACV_2022_paper.pdf)
* å›¾åƒæ¢å¤
  * [Training a Task-Specific Image Reconstruction Loss](https://arxiv.org/abs/2103.14616)
  * [Image Restoration by Deep Projected GSURE](https://openaccess.thecvf.com/content/WACV2022/papers/Abu-Hussein_Image_Restoration_by_Deep_Projected_GSURE_WACV_2022_paper.pdf)
* å›¾åƒé™è´¨
  * [Deep Photo Scan: Semi-Supervised Learning for dealing with the real-world degradation in Smartphone Photo Scanning](https://arxiv.org/abs/2102.06120)<br>:star:[code](https://github.com/minhmanho/dpscan):house:[project](https://minhmanho.github.io/dpscan/)

## 7.Human Pose(äººä½“å§¿æ€)
* äººä½“åŠ¨ä½œåˆæˆ
  * [Generative Adversarial Graph Convolutional Networks for Human Action Synthesis](https://arxiv.org/abs/2110.11191)<br>:star:[code](https://github.com/DegardinBruno/Kinetic-GAN)
* 3Däººä½“
  * [Matching and Recovering 3D People From Multiple Views](https://openaccess.thecvf.com/content/WACV2022/papers/Perez-Yus_Matching_and_Recovering_3D_People_From_Multiple_Views_WACV_2022_paper.pdf)
* äººä½“å§¿æ€ä¼°è®¡
  * [Transfer Learning for Pose Estimation of Illustrated Characters](https://arxiv.org/abs/2108.01819)
  * [PERF-Net: Pose Empowered RGB-Flow Net](https://openaccess.thecvf.com/content/WACV2022/papers/Li_PERF-Net_Pose_Empowered_RGB-Flow_Net_WACV_2022_paper.pdf)
* 3Dæ‰‹éƒ¨å§¿åŠ¿ä¼°è®¡
  * [Dynamic Iterative Refinement for Efficient 3D Hand Pose Estimation](https://arxiv.org/abs/2111.06500)
* å¤´éƒ¨å§¿åŠ¿ä¼°è®¡
  * [LwPosr: Lightweight Efficient Fine Grained Head Pose Estimation](https://openaccess.thecvf.com/content/WACV2022/papers/Dhingra_LwPosr_Lightweight_Efficient_Fine_Grained_Head_Pose_Estimation_WACV_2022_paper.pdf)

## 6.Video
* æ— ç›‘ç£è§†é¢‘åŸŸé€‚åº”
  * [Multi-Level Attentive Adversarial Learning With Temporal Dilation for Unsupervised Video Domain Adaptation](https://openaccess.thecvf.com/content/WACV2022/papers/Chen_Multi-Level_Attentive_Adversarial_Learning_With_Temporal_Dilation_for_Unsupervised_Video_WACV_2022_paper.pdf)
* Partial Video Copy Detection(å±€éƒ¨è§†é¢‘æ‹·è´æ£€æµ‹)
  * [A Fast Partial Video Copy Detection Using KNN and Global Feature Database](https://arxiv.org/abs/2105.01713)
* å¼‚å¸¸æ£€æµ‹
  * [Discrete Neural Representations for Explainable Anomaly Detection](https://arxiv.org/abs/2112.05585)<br>:house:[project](http://jjcvision.com/projects/vqunet_anomally_detection.html):tv:[video](https://youtu.be/3KLRi0biQvY)
  * [Rethinking Video Anomaly Detection - A Continual Learning Approach](https://openaccess.thecvf.com/content/WACV2022/papers/Doshi_Rethinking_Video_Anomaly_Detection_-_A_Continual_Learning_Approach_WACV_2022_paper.pdf)
* sarcasm and humor detection(è®½åˆºä¸å¹½é»˜æ£€æµ‹)
  * [Multimodal Learning using Optimal Transport for Sarcasm and Humor Detection](https://arxiv.org/abs/2110.10949)
* è§†é¢‘è¡¨å¾å­¦ä¹ 
  * [Hierarchically Decoupled Spatial-Temporal Contrast for Self-Supervised Video Representation Learning](https://arxiv.org/abs/2011.11261)

## 5.Object Detection(ç›®æ ‡æ£€æµ‹)
* [Meta-UDA: Unsupervised Domain Adaptive Thermal Object Detection Using Meta-Learning](https://openaccess.thecvf.com/content/WACV2022/papers/VS_Meta-UDA_Unsupervised_Domain_Adaptive_Thermal_Object_Detection_Using_Meta-Learning_WACV_2022_paper.pdf)
* [ADC: Adversarial Attacks Against Object Detection That Evade Context Consistency Checks](https://arxiv.org/abs/2110.12321)
* ç›®æ ‡å®šä½
  * æ— ç›‘ç£ç›®æ ‡å®šä½
    * [F-CAM: Full Resolution Class Activation Maps via Guided Parametric Upscaling](https://openaccess.thecvf.com/content/WACV2022/papers/Belharbi_F-CAM_Full_Resolution_Class_Activation_Maps_via_Guided_Parametric_Upscaling_WACV_2022_paper.pdf)<br>:star:[code](https://github.com/sbelharbi/fcam-wsol)
* MOD(ç§»åŠ¨ç›®æ ‡æ£€æµ‹)
  * [Multi-Motion and Appearance Self-Supervised Moving Object Detection](https://openaccess.thecvf.com/content/WACV2022/papers/Yang_Multi-Motion_and_Appearance_Self-Supervised_Moving_Object_Detection_WACV_2022_paper.pdf)
* è·¯æ ‡æ£€æµ‹
  * [CeyMo: See More on Roads - A Novel Benchmark Dataset for Road Marking Detection](https://openaccess.thecvf.com/content/WACV2022/papers/Jayasinghe_CeyMo_See_More_on_Roads_-_A_Novel_Benchmark_Dataset_WACV_2022_paper.pdf)<br>:star:[code](https://github.com/oshadajay/CeyMo)
* é›¶æ ·æœ¬æ£€æµ‹
  * [From Node To Graph: Joint Reasoning on Visual-Semantic Relational Graph for Zero-Shot Detection](https://openaccess.thecvf.com/content/WACV2022/papers/Nie_From_Node_To_Graph_Joint_Reasoning_on_Visual-Semantic_Relational_Graph_WACV_2022_paper.pdf)
* å›¾åƒå¼‚å¸¸æ£€æµ‹
  * [Multi-Scale Patch-Based Representation Learning for Image Anomaly Detection and Segmentation](https://openaccess.thecvf.com/content/WACV2022/papers/Tsai_Multi-Scale_Patch-Based_Representation_Learning_for_Image_Anomaly_Detection_and_Segmentation_WACV_2022_paper.pdf)
* å¼±ç›‘ç£ç›®æ ‡æ£€æµ‹
 * [Few-Shot Weakly-Supervised Object Detection via Directional Statistics](https://arxiv.org/abs/2103.14162)


## 4.GAN(ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ)
* [GraN-GAN: Piecewise Gradient Normalization for Generative Adversarial Networks](https://openaccess.thecvf.com/content/WACV2022/papers/Bhaskara_GraN-GAN_Piecewise_Gradient_Normalization_for_Generative_Adversarial_Networks_WACV_2022_paper.pdf)
* [Latent to Latent: A Learned Mapper for Identity Preserving Editing of Multiple Face Attributes in StyleGAN-Generated Images](https://openaccess.thecvf.com/content/WACV2022/papers/Khodadadeh_Latent_to_Latent_A_Learned_Mapper_for_Identity_Preserving_Editing_WACV_2022_paper.pdf)
* [AE-StyleGAN: Improved Training of Style-Based Auto-Encoders](https://openaccess.thecvf.com/content/WACV2022/papers/Han_AE-StyleGAN_Improved_Training_of_Style-Based_Auto-Encoders_WACV_2022_paper.pdf)<br>:star:[code](https://github.com/phymhan/stylegan2-pytorch)

## 3.3D(ä¸‰ç»´è§†è§‰)
* æ·±åº¦ä¼°è®¡
  * [SIDE: Center-Based Stereo 3D Detector With Structure-Aware Instance Depth Estimation](https://arxiv.org/abs/2108.09663)
* stereo images
  * [SBEVNet: End-to-End Deep Stereo Layout Estimation](https://arxiv.org/abs/2105.11705)<br>:star:[code](https://github.com/divamgupta/sbevnet-stereo-layout-estimation)
* ä¸‰ç»´é‡å»º
  * [Single-Shot Dense Active Stereo With Pixel-Wise Phase Estimation Based on Grid-Structure Using CNN and Correspondence Estimation Using GCN](https://openaccess.thecvf.com/content/WACV2022/papers/Furukawa_Single-Shot_Dense_Active_Stereo_With_Pixel-Wise_Phase_Estimation_Based_on_WACV_2022_paper.pdf)


<a name="2"/>

## 2.Medical Image(åŒ»å­¦å½±åƒ)
* åŒ»å­¦å›¾åƒåˆ†å‰²
  * [UNETR: Transformers for 3D Medical Image Segmentation](https://arxiv.org/abs/2103.10504)<br>:star:[code](https://github.com/Project-MONAI/research-contributions/tree/master/UNETR)
* åŒ»å­¦å›¾åƒæ£€ç´¢
  * [X-MIR: EXplainable Medical Image Retrieval](https://openaccess.thecvf.com/content/WACV2022/papers/Hu_X-MIR_EXplainable_Medical_Image_Retrieval_WACV_2022_paper.pdf)<br>:star:[code](https://gitlab.kitware.com/brianhhu/x-mir)

<a name="1"/>

## 1.å…¶å®ƒ
* [Does Data Repair Lead to Fair Models? Curating Contextually Fair Data To Reduce Model Bias](https://arxiv.org/abs/2110.10389)<br>:star:[code](https://github.com/sumanyumuku98/contextual-bias)
* [The Untapped Potential of Off-the-Shelf Convolutional Neural Networks](https://arxiv.org/abs/2103.09891)
* [Unveiling Real-Life Effects of Online Photo Sharing](https://openaccess.thecvf.com/content/WACV2022/papers/Nguyen_Unveiling_Real-Life_Effects_of_Online_Photo_Sharing_WACV_2022_paper.pdf)
* [Shadow Art Revisited: A Differentiable Rendering Based Approach](https://arxiv.org/abs/2107.14539)
* [Towards Class-Oriented Poisoning Attacks Against Neural Networks](https://arxiv.org/abs/2008.00047)
* [Predicting Levels of Household Electricity Consumption in Low-Access Settings](https://arxiv.org/abs/2112.08497)
* [Neural Radiance Fields Approach to Deep Multi-View Photometric Stereo](https://arxiv.org/abs/2110.05594)
* [PRECODE - A Generic Model Extension To Prevent Deep Gradient Leakage](https://openaccess.thecvf.com/content/WACV2022/papers/Scheliga_PRECODE_-_A_Generic_Model_Extension_To_Prevent_Deep_Gradient_WACV_2022_paper.pdf)
* [Discovering Underground Maps From Fashion](https://arxiv.org/abs/2012.02897)
* [On the Maximum Radius of Polynomial Lens Distortion](https://openaccess.thecvf.com/content/WACV2022/papers/Leotta_On_the_Maximum_Radius_of_Polynomial_Lens_Distortion_WACV_2022_paper.pdf)<br>:star:[code](https://github.com/Kitware/max-lens-radius)
* [The Hitchhiker's Guide to Prior-Shift Adaptation](https://openaccess.thecvf.com/content/WACV2022/papers/Sipka_The_Hitchhikers_Guide_to_Prior-Shift_Adaptation_WACV_2022_paper.pdf)<br>:star:[code](https://github.com/sipkatom/The-Hitchhiker-s-Guide-to-Prior-Shift-Adaptation)
* [FalCon: Fine-Grained Feature Map Sparsity Computing With Decomposed Convolutions for Inference Optimization](https://openaccess.thecvf.com/content/WACV2022/papers/Xu_FalCon_Fine-Grained_Feature_Map_Sparsity_Computing_With_Decomposed_Convolutions_for_WACV_2022_paper.pdf)
* [METGAN: Generative Tumour Inpainting and Modality Synthesis in Light Sheet Microscopy](https://arxiv.org/abs/2104.10993)
* [Agree To Disagree: When Deep Learning Models With Identical Architectures Produce Distinct Explanations](https://arxiv.org/abs/2105.06791)<br>:star:[code](https://github.com/mattswatson/agree-to-disagree)
* [REFICS: A Step Towards Linking Vision With Hardware Assurance](https://openaccess.thecvf.com/content/WACV2022/papers/Wilson_REFICS_A_Step_Towards_Linking_Vision_With_Hardware_Assurance_WACV_2022_paper.pdf)
* [Deep Optimization Prior for THz Model Parameter Estimation](https://openaccess.thecvf.com/content/WACV2022/papers/Wong_Deep_Optimization_Prior_for_THz_Model_Parameter_Estimation_WACV_2022_paper.pdf)
* [Sharing Decoders: Network Fission for Multi-Task Pixel Prediction](https://openaccess.thecvf.com/content/WACV2022/papers/Hickson_Sharing_Decoders_Network_Fission_for_Multi-Task_Pixel_Prediction_WACV_2022_paper.pdf)
